# HTML File Scraper

This application was initially developed as a group project for my CS350 course at Old Dominion University. I have removed all code that I did not write myself and have further developed the project.

When run, the application takes a single directory location and list of URLs from a commmand line. It outputs two files: a text file of HTML pages sorted lexicographically by directory starting with the site root with the format mirroring the output of the Linux du command (ie: du -h --max-depth 1) and an excel file 

![Alt text](initial_uml.svg?raw=true "Title")

Original project repo [here](https://github.com/dbail014/Offline-Web-Analysis), with other contributor githubs below:
- johnwasikye
- dbail014
- aclar074
